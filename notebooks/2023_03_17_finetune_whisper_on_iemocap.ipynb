{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## init"
      ],
      "metadata": {
        "id": "JWxbRKGh3RzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qqq transformers torchaudio datasets wandb"
      ],
      "metadata": {
        "id": "RCAHK5kxBSHF",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:47:52.987833Z",
          "iopub.execute_input": "2023-03-17T18:47:52.988776Z",
          "iopub.status.idle": "2023-03-17T18:48:05.537290Z",
          "shell.execute_reply.started": "2023-03-17T18:47:52.988730Z",
          "shell.execute_reply": "2023-03-17T18:48:05.535931Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os"
      ],
      "metadata": {
        "id": "u3xkTBGt2cwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# env variables\n",
        "DRIVE_MOUNT_PATH = \"/content/drive\"\n",
        "DATA_PATH = f\"{DRIVE_MOUNT_PATH}/MyDrive/Shared/data\"\n",
        "OUTPUT_DIR = \"/content/wav2vec2-iemocap-speech-emotion-recognition\"\n",
        "%env WANDB_WATCH=all\n",
        "%env WANDB_LOG_MODEL=checkpoint"
      ],
      "metadata": {
        "id": "FzihRGsm7LxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(DRIVE_MOUNT_PATH)"
      ],
      "metadata": {
        "id": "NXRXdQHm7LxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use OpenAI's whisper for speech emotion recognition on IEMOCAP dataset**\n",
        "---\n",
        "- ðŸš€ **objective**: run whisper as a feature extractor on IEMOCAP dataset, requires the data preprocessing of IEMOCAP dataset  \n",
        "- ðŸ§¯ **models**: whisper\n",
        "- ðŸ“š **dataset**: IEMOCAP\n",
        "\n",
        "Whisper model card in HuggingFace https://huggingface.co/docs/transformers/model_doc/whisper"
      ],
      "metadata": {
        "id": "ebaFEkvH3R6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ configuration"
      ],
      "metadata": {
        "id": "VTM5mAoeArCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "E5slPz53BPEB",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:09.165320Z",
          "iopub.execute_input": "2023-03-17T18:48:09.165604Z",
          "iopub.status.idle": "2023-03-17T18:48:19.527601Z",
          "shell.execute_reply.started": "2023-03-17T18:48:09.165569Z",
          "shell.execute_reply": "2023-03-17T18:48:19.526502Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"openai/whisper-base\"\n",
        "feature_to_idx = {key: i for i, key in enumerate([\"wav\", \"sampling_rate\", \"filename\", \"label\", \"speaker\"])}\n",
        "label_list = [\"neu\", \"hap\", \"ang\", \"sad\", \"exc\", \"fru\"]\n",
        "num_labels = len(label_list)\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "pooling_mode = \"max\"\n",
        "test_split_size = 0.2\n",
        "target_sampling_rate = 16000\n",
        "\n",
        "DEBUG_SIZE = 0.1 # percentage of the whole dataset\n",
        "\n",
        "metrics = {\n",
        "  \"unweighted_accuracy\": accuracy_score,\n",
        "  \"weighted_accuracy\": balanced_accuracy_score,\n",
        "  \"micro_f1\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"micro\"),\n",
        "  \"macro_f1\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")\n",
        "}"
      ],
      "metadata": {
        "id": "c9FAPgXIKa04",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:19.529996Z",
          "iopub.execute_input": "2023-03-17T18:48:19.530637Z",
          "iopub.status.idle": "2023-03-17T18:48:19.539532Z",
          "shell.execute_reply.started": "2023-03-17T18:48:19.530607Z",
          "shell.execute_reply": "2023-03-17T18:48:19.538407Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    label_names=label_list,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    evaluation_strategy=\"steps\", # should enable do_eval\n",
        "    num_train_epochs=1.0,\n",
        "    learning_rate=1e-4,\n",
        "    fp16=torch.cuda.is_available(), # whether to use fp16 16-bit (mixed) precision training instead of 32-bit training\n",
        "    save_steps=100,\n",
        "    eval_steps=10,\n",
        "    logging_steps=50,\n",
        "#     report_to=\"wandb\",\n",
        "    report_to=[],\n",
        "    half_precision_backend=\"auto\", # shoud be 'cuda_amp' half precision backend\n",
        "    gradient_checkpointing=True, # use gradient checkpointing to save memory at the expense of slower backward pass\n",
        ")"
      ],
      "metadata": {
        "id": "OeMVreG3-6qs",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:19.541398Z",
          "iopub.execute_input": "2023-03-17T18:48:19.542190Z",
          "iopub.status.idle": "2023-03-17T18:48:19.625863Z",
          "shell.execute_reply.started": "2023-03-17T18:48:19.542154Z",
          "shell.execute_reply": "2023-03-17T18:48:19.624923Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š data\n",
        "- ~torchaudio implemented a `dataset` to load IEMOCAP. Later in the script, we train the model with a `Trainer` from hugginface, therefore we prefer translating the pytorch dataset into a `transformers.Dataset` for convenience and compatibility.~\n",
        "- the Trainer class expects an argument `train_dataset` to be of type torch.utils.data.Dataset (see [documentation](https://huggingface.co/docs/transformers/main_classes/trainer)) --> we use a torch dataset instead of a Hugginface dataset"
      ],
      "metadata": {
        "id": "w9lfgKcGHlQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/audio/master/generated/torchaudio.datasets.IEMOCAP.html\n",
        "from torchaudio.datasets import IEMOCAP\n",
        "\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split, Dataset, DataLoader, SubsetRandomSampler"
      ],
      "metadata": {
        "id": "63mPgt-MR8p0",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:19.628643Z",
          "iopub.execute_input": "2023-03-17T18:48:19.629001Z",
          "iopub.status.idle": "2023-03-17T18:48:20.213392Z",
          "shell.execute_reply.started": "2023-03-17T18:48:19.628965Z",
          "shell.execute_reply": "2023-03-17T18:48:20.212198Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = WhisperProcessor.from_pretrained(model_name_or_path)\n",
        "target_sampling_rate = processor.feature_extractor.sampling_rate"
      ],
      "metadata": {
        "id": "3h-qBGonTgmf",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:20.215626Z",
          "iopub.execute_input": "2023-03-17T18:48:20.216014Z",
          "iopub.status.idle": "2023-03-17T18:48:23.515935Z",
          "shell.execute_reply.started": "2023-03-17T18:48:20.215972Z",
          "shell.execute_reply": "2023-03-17T18:48:23.514698Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomIEMOCAP(Dataset):\n",
        "  def __init__(self, data, processor):\n",
        "    self.data = data\n",
        "    self.processor = processor\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    wav, _, _, label, _ = self.data[index]\n",
        "    inputs = self.processor(wav.squeeze(), sampling_rate=target_sampling_rate)\n",
        "    inputs[\"labels\"] = label2id[label]\n",
        "\n",
        "    return inputs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "lEkXSO7-wI2t",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:23.517585Z",
          "iopub.execute_input": "2023-03-17T18:48:23.518305Z",
          "iopub.status.idle": "2023-03-17T18:48:23.528744Z",
          "shell.execute_reply.started": "2023-03-17T18:48:23.518265Z",
          "shell.execute_reply": "2023-03-17T18:48:23.527673Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iemocap = IEMOCAP(root=DATA_PATH) # in function, path = root / \"IEMOCAP\"\n",
        "iemocap = torch.utils.data.Subset(iemocap, range(int(DEBUG_SIZE * len(iemocap)))) # DEBUG\n",
        "\n",
        "dataset = CustomIEMOCAP(data=iemocap, processor=processor)\n",
        "train_ds, test_ds = random_split(dataset, [1-test_split_size, test_split_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "dataset[0]"
      ],
      "metadata": {
        "id": "TkLW4D2ZwYCl",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:23.534342Z",
          "iopub.execute_input": "2023-03-17T18:48:23.535066Z",
          "iopub.status.idle": "2023-03-17T18:48:26.929671Z",
          "shell.execute_reply.started": "2023-03-17T18:48:23.535029Z",
          "shell.execute_reply": "2023-03-17T18:48:26.927955Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸšœ model definition"
      ],
      "metadata": {
        "id": "_DZWd3CGHnnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperModel, PreTrainedModel\n",
        "from transformers import AutoConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "metadata": {
        "id": "OAJrSE-vR4OO",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:26.931544Z",
          "iopub.execute_input": "2023-03-17T18:48:26.932135Z",
          "iopub.status.idle": "2023-03-17T18:48:27.509803Z",
          "shell.execute_reply.started": "2023-03-17T18:48:26.932088Z",
          "shell.execute_reply": "2023-03-17T18:48:27.508786Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "config = AutoConfig.from_pretrained(\n",
        "  model_name_or_path,\n",
        "  num_labels=num_labels,\n",
        "  label2id=label2id,\n",
        "  id2label=id2label,\n",
        ")\n",
        "setattr(config, 'pooling_mode', pooling_mode)\n",
        "config"
      ],
      "metadata": {
        "id": "a-JbmAoyT6v0",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:27.514759Z",
          "iopub.execute_input": "2023-03-17T18:48:27.517088Z",
          "iopub.status.idle": "2023-03-17T18:48:27.802076Z",
          "shell.execute_reply.started": "2023-03-17T18:48:27.517049Z",
          "shell.execute_reply": "2023-03-17T18:48:27.800952Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Union, Tuple\n",
        "from transformers.file_utils import ModelOutput\n",
        "\n",
        "@dataclass\n",
        "class SpeechClassifierOutput(ModelOutput):\n",
        "    loss: Optional[torch.FloatTensor] = None\n",
        "    logits: torch.FloatTensor = None\n",
        "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
        "    attentions: Optional[Tuple[torch.FloatTensor]] = None"
      ],
      "metadata": {
        "id": "54M_I54lQ-QJ",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:27.803674Z",
          "iopub.execute_input": "2023-03-17T18:48:27.804356Z",
          "iopub.status.idle": "2023-03-17T18:48:27.815971Z",
          "shell.execute_reply.started": "2023-03-17T18:48:27.804317Z",
          "shell.execute_reply": "2023-03-17T18:48:27.814769Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperPreTrainedModel\n",
        "\n",
        "class WhisperClassificationHead(nn.Module):\n",
        "  \"\"\"Head for whisper classification task.\"\"\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "    self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "  def forward(self, features, **kwargs):\n",
        "    x = features\n",
        "    x = self.dropout(x)\n",
        "    x = self.dense(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.out_proj(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class WhisperForSpeechClassification(WhisperPreTrainedModel):\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.num_labels = config.num_labels\n",
        "    self.pooling_mode = config.pooling_mode\n",
        "    self.config = config\n",
        "\n",
        "    self.whisper = WhisperModel(config).encoder\n",
        "    self.classifier = WhisperClassificationHead(config)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def freeze_encoder(self):\n",
        "    self.whisper._freeze_parameters()\n",
        "\n",
        "  def merged_strategy(\n",
        "      \n",
        "      self,\n",
        "      hidden_states,\n",
        "      mode=\"mean\"\n",
        "  ):\n",
        "    if mode == \"mean\":\n",
        "        outputs = torch.mean(hidden_states, dim=1)\n",
        "    elif mode == \"sum\":\n",
        "        outputs = torch.sum(hidden_states, dim=1)\n",
        "    elif mode == \"max\":\n",
        "        outputs = torch.max(hidden_states, dim=1)[0]\n",
        "    else:\n",
        "        raise Exception(\n",
        "            \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      input_features,\n",
        "      attention_mask=None,\n",
        "      output_attentions=None,\n",
        "      output_hidden_states=None,\n",
        "      return_dict=None,\n",
        "      labels=None,\n",
        "  ):\n",
        "    return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "    outputs = self.whisper(\n",
        "        input_features,\n",
        "        attention_mask=attention_mask,\n",
        "        output_attentions=output_attentions,\n",
        "        output_hidden_states=output_hidden_states,\n",
        "        return_dict=return_dict,\n",
        "    )\n",
        "    hidden_states = outputs[0]\n",
        "    hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
        "    logits = self.classifier(hidden_states)\n",
        "\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "    if not return_dict:\n",
        "      output = (logits,) + outputs[2:]\n",
        "      return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "    return SpeechClassifierOutput(\n",
        "      loss=loss,\n",
        "      logits=logits,\n",
        "      hidden_states=outputs.hidden_states,\n",
        "      attentions=outputs.attentions,\n",
        "    )"
      ],
      "metadata": {
        "id": "P1HzzCqPAuSH",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:27.817905Z",
          "iopub.execute_input": "2023-03-17T18:48:27.818618Z",
          "iopub.status.idle": "2023-03-17T18:48:27.846374Z",
          "shell.execute_reply.started": "2023-03-17T18:48:27.818572Z",
          "shell.execute_reply": "2023-03-17T18:48:27.845326Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WhisperForSpeechClassification.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "id": "C7aPeO-fGBt-",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:27.851034Z",
          "iopub.execute_input": "2023-03-17T18:48:27.853630Z",
          "iopub.status.idle": "2023-03-17T18:48:31.186841Z",
          "shell.execute_reply.started": "2023-03-17T18:48:27.853585Z",
          "shell.execute_reply": "2023-03-17T18:48:31.185905Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.freeze_encoder()\n",
        "model"
      ],
      "metadata": {
        "id": "qlYFwx5XTCjE",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:31.188355Z",
          "iopub.execute_input": "2023-03-17T18:48:31.188940Z",
          "iopub.status.idle": "2023-03-17T18:48:31.199008Z",
          "shell.execute_reply.started": "2023-03-17T18:48:31.188898Z",
          "shell.execute_reply": "2023-03-17T18:48:31.197890Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸƒâ€â™€ï¸ training routine"
      ],
      "metadata": {
        "id": "hpjqc0qlH5u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, Union, Tuple, Optional\n",
        "from packaging import version\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from transformers import Trainer, is_apex_available, WhisperProcessor, EvalPrediction\n",
        "\n",
        "if is_apex_available():\n",
        "    from apex import amp \n",
        "    # Apex is a PyTorch add-on package from NVIDIA with capabilities for automatic mixed precision (AMP) and distributed training.\n",
        "    # https://www.ibm.com/docs/en/wmlce/1.6.1?topic=frameworks-getting-started-apex\n",
        "\n",
        "if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n",
        "  _is_native_amp_available = True\n",
        "  from torch.cuda.amp import autocast"
      ],
      "metadata": {
        "id": "3frD5uDaR872",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:48:31.200516Z",
          "iopub.execute_input": "2023-03-17T18:48:31.201679Z",
          "iopub.status.idle": "2023-03-17T18:48:31.689514Z",
          "shell.execute_reply.started": "2023-03-17T18:48:31.201637Z",
          "shell.execute_reply": "2023-03-17T18:48:31.688278Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "  processor: WhisperProcessor\n",
        "  padding: Union[bool, str] = True\n",
        "  max_length: Optional[int] = None\n",
        "  max_length_labels: Optional[int] = None\n",
        "  pad_to_multiple_of: Optional[int] = None\n",
        "  pad_to_multiple_of_labels: Optional[int] = None\n",
        "\n",
        "  def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "    input_features = [{\"input_features\": feature[\"input_features\"][0]} for feature in features]\n",
        "    label_features = [feature[\"labels\"] for feature in features]\n",
        "\n",
        "    d_type = torch.long if isinstance(label_features[0], int) else torch.float\n",
        "\n",
        "    batch = self.processor.feature_extractor.pad(\n",
        "      input_features,\n",
        "      padding=self.padding,\n",
        "      max_length=self.max_length,\n",
        "      pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "      return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    batch[\"labels\"] = torch.tensor(label_features, dtype=d_type)\n",
        "    return batch"
      ],
      "metadata": {
        "id": "goTHilxaR3R5",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:10.461197Z",
          "iopub.execute_input": "2023-03-17T18:53:10.461605Z",
          "iopub.status.idle": "2023-03-17T18:53:10.474401Z",
          "shell.execute_reply.started": "2023-03-17T18:53:10.461569Z",
          "shell.execute_reply": "2023-03-17T18:53:10.473028Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    # (preds == p.label_ids).astype(np.float32).mean().item()\n",
        "    return {k: metric(p.label_ids, preds) for k, metric in metrics.items()}"
      ],
      "metadata": {
        "id": "mqZbCzVJSmMP",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:10.478558Z",
          "iopub.execute_input": "2023-03-17T18:53:10.479757Z",
          "iopub.status.idle": "2023-03-17T18:53:10.492789Z",
          "shell.execute_reply.started": "2023-03-17T18:53:10.479721Z",
          "shell.execute_reply": "2023-03-17T18:53:10.491714Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCTrainer(Trainer):\n",
        "  def training_step(self, model, inputs) -> torch.Tensor:\n",
        "    model.train()\n",
        "    inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "    with autocast():\n",
        "      # loss = self.compute_loss(model, inputs)\n",
        "      loss = model(**inputs).get(\"loss\")\n",
        "\n",
        "    if self.args.gradient_accumulation_steps > 1:\n",
        "      loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "    self.scaler.scale(loss).backward()\n",
        "\n",
        "    return loss.detach()\n",
        "  \n",
        "  def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys) -> torch.Tensor: \n",
        "    model.eval()\n",
        "    inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "    labels = inputs.get(\"labels\")\n",
        "\n",
        "    with autocast():\n",
        "      outputs = model(**inputs)\n",
        "      logits = outputs.get(\"logits\")\n",
        "      loss = outputs.get(\"loss\")\n",
        "\n",
        "    if self.args.gradient_accumulation_steps > 1:\n",
        "      loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "    self.scaler.scale(loss).backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    if prediction_loss_only:\n",
        "      return loss.detach()\n",
        "    return (loss.detach(), logits.detach(), labels.detach())"
      ],
      "metadata": {
        "id": "5NxWSqMKGkRr",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:10.496566Z",
          "iopub.execute_input": "2023-03-17T18:53:10.496986Z",
          "iopub.status.idle": "2023-03-17T18:53:10.509745Z",
          "shell.execute_reply.started": "2023-03-17T18:53:10.496955Z",
          "shell.execute_reply": "2023-03-17T18:53:10.508524Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
      ],
      "metadata": {
        "id": "eH9EZ7o3SWip",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:10.511900Z",
          "iopub.execute_input": "2023-03-17T18:53:10.513203Z",
          "iopub.status.idle": "2023-03-17T18:53:10.521798Z",
          "shell.execute_reply.started": "2023-03-17T18:53:10.513159Z",
          "shell.execute_reply": "2023-03-17T18:53:10.520743Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "trainer = CTCTrainer(\n",
        "  model=model,\n",
        "  data_collator=data_collator,\n",
        "  args=training_args,\n",
        "  compute_metrics=compute_metrics,\n",
        "  train_dataset=train_ds,\n",
        "  eval_dataset=test_ds,\n",
        "  tokenizer=processor.feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "id": "d1lLo-_vG8ih",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:10.525163Z",
          "iopub.execute_input": "2023-03-17T18:53:10.525667Z",
          "iopub.status.idle": "2023-03-17T18:53:10.538479Z",
          "shell.execute_reply.started": "2023-03-17T18:53:10.525619Z",
          "shell.execute_reply": "2023-03-17T18:53:10.537180Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§ª experiments"
      ],
      "metadata": {
        "id": "QKJKwY4_IFCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "D9piW_jCHBav",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:10.540692Z",
          "iopub.execute_input": "2023-03-17T18:53:10.541110Z",
          "iopub.status.idle": "2023-03-17T18:53:11.126939Z",
          "shell.execute_reply.started": "2023-03-17T18:53:10.541071Z",
          "shell.execute_reply": "2023-03-17T18:53:11.125108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "6y9pes7RLINI",
        "execution": {
          "iopub.status.busy": "2023-03-17T18:53:11.128420Z",
          "iopub.status.idle": "2023-03-17T18:53:11.130095Z",
          "shell.execute_reply.started": "2023-03-17T18:53:11.129573Z",
          "shell.execute_reply": "2023-03-17T18:53:11.129609Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}